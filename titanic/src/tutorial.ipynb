{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37564bitb7d151babcae48fb9576059ff7567d23",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PassengerId  Survived  Pclass  \\\n0              1         0       3   \n1              2         1       1   \n2              3         1       3   \n3              4         1       1   \n4              5         0       3   \n..           ...       ...     ...   \n886          887         0       2   \n887          888         1       1   \n888          889         0       3   \n889          890         1       1   \n890          891         0       3   \n\n                                                  Name     Sex   Age  SibSp  \\\n0                              Braund, Mr. Owen Harris    male  22.0      1   \n1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                               Heikkinen, Miss. Laina  female  26.0      0   \n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                             Allen, Mr. William Henry    male  35.0      0   \n..                                                 ...     ...   ...    ...   \n886                              Montvila, Rev. Juozas    male  27.0      0   \n887                       Graham, Miss. Margaret Edith  female  19.0      0   \n888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n889                              Behr, Mr. Karl Howell    male  26.0      0   \n890                                Dooley, Mr. Patrick    male  32.0      0   \n\n     Parch            Ticket     Fare Cabin Embarked  \n0        0         A/5 21171   7.2500   NaN        S  \n1        0          PC 17599  71.2833   C85        C  \n2        0  STON/O2. 3101282   7.9250   NaN        S  \n3        0            113803  53.1000  C123        S  \n4        0            373450   8.0500   NaN        S  \n..     ...               ...      ...   ...      ...  \n886      0            211536  13.0000   NaN        S  \n887      0            112053  30.0000   B42        S  \n888      2        W./C. 6607  23.4500   NaN        S  \n889      0            111369  30.0000  C148        C  \n890      0            370376   7.7500   NaN        Q  \n\n[891 rows x 12 columns]\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from settings import *  # contain data path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read dataset from TRAIN_PATH\n",
    "train_data = pd.read_csv(TRAIN_PATH)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which features are available in the dataset?\n",
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which features are numerical?\n",
    "print(train_data.describe(include=[int, float]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which features are categorical?\n",
    "print(train_data.describe(include=[object]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which features contain blank, null or empty values?\n",
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as you can see cabin has so many null value ~77% so you can drop cabin\n",
    "train_data = train_data.drop(['Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PassengerId, Name have cont contribute to goal of problem(survived) so we can also drop them\n",
    "train_data = train_data.drop(['PassengerId', 'Name'], axis=1)\n",
    "print(train_data.describe(include=[object]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ticket has 681 unique value which is so many.\n",
    "# so we have struggle to encode that to numerical.\n",
    "# so i think it is better to drop it too.\n",
    "train_data = train_data.drop(['Ticket'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is our final dataset till now\n",
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age and Embarked have null value. so we sould deal with them.\n",
    "# fill Embarked with most the most common occurance.\n",
    "freq_port = train_data.Embarked.dropna().mode()[0]\n",
    "train_data['Embarked'] = train_data['Embarked'].fillna(freq_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now convert Embarked to numerical\n",
    "train_data['Embarked'] = train_data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill Age with respect of other feature correlation.\n",
    "grid = sns.FacetGrid(train_data, col='Sex', row='Pclass', size=2.2, aspect=1.6)\n",
    "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
    "grid.add_legend();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with respect of the above charts you can see correlation between age, sex and pclass.\n",
    "# so we can fill age null values with respect of pclass and sex.\n",
    "# but before that we should convert categorical value of sex to numerical\n",
    "train_data['Sex'] = train_data['Sex'].map({'female': 1, 'male': 0}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so now we can fill null values of age\n",
    "guess_ages = np.zeros((2, 3))\n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "\n",
    "        guess_df = train_data[(train_data['Sex'] == i) & \\\n",
    "                           (train_data['Pclass'] == j + 1)]['Age'].dropna()\n",
    "\n",
    "        age_guess = guess_df.median()\n",
    "\n",
    "        # Convert random age float to nearest .5 age\n",
    "        guess_ages[i, j] = int(age_guess / 0.5 + 0.5) * 0.5\n",
    "\n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        train_data.loc[(train_data.Age.isnull()) & (train_data.Sex == i) & (train_data.Pclass == j + 1), \\\n",
    "                    'Age'] = guess_ages[i, j]\n",
    "\n",
    "train_data['Age'] = train_data['Age'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We may want to create new feature for Age bands. This turns a continous numerical feature into an ordinal categorical feature.\n",
    "train_data['AgeBand'] = pd.cut(train_data['Age'], 5)\n",
    "print(train_data[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand',\n",
    "                                                                                                  ascending=True))\n",
    "train_data.loc[ train_data['Age'] <= 16, 'Age'] = 0\n",
    "train_data.loc[(train_data['Age'] > 16) & (train_data['Age'] <= 32), 'Age'] = 1\n",
    "train_data.loc[(train_data['Age'] > 32) & (train_data['Age'] <= 48), 'Age'] = 2\n",
    "train_data.loc[(train_data['Age'] > 48) & (train_data['Age'] <= 64), 'Age'] = 3\n",
    "train_data.loc[ train_data['Age'] > 64, 'Age'] = 4\n",
    "\n",
    "train_data = train_data.drop(['AgeBand'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We may want to create a new feature called Family based on Parch and SibSp to get total count of family members on board.\n",
    "train_data['FamilySize'] = train_data['SibSp'] + train_data['Parch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets have some analyze\n",
    "print(train_data[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived',\n",
    "                                                                                                      ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can create another feature called IsAlone.\n",
    "train_data['IsAlone'] = 0\n",
    "train_data.loc[train_data['FamilySize'] == 1, 'IsAlone'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets have some analyze on IsAlone\n",
    "print(train_data[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us drop Parch, SibSp, and FamilySize features in favor of IsAlone.\n",
    "train_data = train_data.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We may also want to create a Fare range feature if it helps our analysis.\n",
    "train_data['FareBand'] = pd.qcut(train_data['Fare'], 4)\n",
    "print(train_data[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand',\n",
    "                                                                                                  ascending=True))\n",
    "train_data.loc[ train_data['Fare'] <= 7.91, 'Fare'] = 0\n",
    "train_data.loc[(train_data['Fare'] > 7.91) & (train_data['Fare'] <= 14.454), 'Fare'] = 1\n",
    "train_data.loc[(train_data['Fare'] > 14.454) & (train_data['Fare'] <= 31), 'Fare']   = 2\n",
    "train_data.loc[ train_data['Fare'] > 31, 'Fare'] = 3\n",
    "train_data['Fare'] = train_data['Fare'].astype(int)\n",
    "\n",
    "train_data = train_data.drop(['FareBand'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to TRAIN and TEST\n",
    "from sklearn.model_selection import train_test_split\n",
    "y_data = train_data.Survived\n",
    "x_data = train_data[[i for i in train_data.keys() if i != 'Survived']]\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_data, y_data, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now feed data to model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(xtrain, ytrain)\n",
    "acc_random_forest = round(random_forest.score(xtrain, ytrain) * 100, 2)\n",
    "print(acc_random_forest)\n",
    "print(round(random_forest.score(xtest, ytest) * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use Pipline to have cleaner code\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "my_pipeline = Pipeline(steps=[\n",
    "    ('model', acc_random_forest)\n",
    "])\n",
    "my_pipeline.fit(xtrain, ytrain)\n",
    "print(my_pipeline.score(xtest, ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network model in this tutorial i do not work on NN so much\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.metrics import binary_crossentropy, binary_accuracy\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(6,), activation='relu', kernel_regularizer=l2(.01), bias_regularizer=l1(.2)))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(1028, activation='relu', kernel_regularizer=l2(.01), bias_regularizer=l1(.2)))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "sgd = Adam(lr=0.001)\n",
    "model.compile(loss=binary_crossentropy, optimizer=sgd,\n",
    "                  metrics=[binary_crossentropy, binary_accuracy])\n",
    "\n",
    "model.fit(xtrain, ytrain,  epochs=700)\n",
    "score = binary_accuracy(ytest, model.predict(xtest))\n",
    "print(score)"
   ]
  }
 ]
}